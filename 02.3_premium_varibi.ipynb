{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import random\n",
    "\n",
    "def extract_important_keywords(input_text, num_keywords=5, randomize=False):\n",
    "    my_stop_words = list(ENGLISH_STOP_WORDS)\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=my_stop_words, min_df=1)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([input_text])\n",
    "    feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "    tfidf_values = tfidf_matrix.toarray()[0]\n",
    "    sorted_indices = tfidf_values.argsort()[::-1]\n",
    "    \n",
    "    if randomize:\n",
    "        top_keywords = feature_names[np.random.choice(sorted_indices, size=num_keywords, replace=False)]\n",
    "    else:\n",
    "        top_keywords = feature_names[sorted_indices][:num_keywords]\n",
    "\n",
    "    return top_keywords.tolist()\n",
    "\n",
    "# Function to extract named entities using SpaCy\n",
    "def extract_named_entities(input_text, randomize=False):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(input_text)\n",
    "    named_entities = [ent.text.lower() for ent in doc.ents]\n",
    "    \n",
    "    if randomize:\n",
    "        named_entities = random.sample(named_entities, len(named_entities) // 2)  # randomly select half of the named entities\n",
    "\n",
    "    return list(set(named_entities))\n",
    "\n",
    "def dynamic_detailed_summarize_premium_varibility(input_text, detail_level=1, context_type='general', important_keywords=None, important_entities=None, randomize=False):\n",
    "    if important_keywords is None:\n",
    "        important_keywords = extract_important_keywords(input_text, randomize=randomize)\n",
    "    \n",
    "    if important_entities is None:\n",
    "        important_entities = extract_named_entities(input_text, randomize=randomize)\n",
    "    print(f\"Important KeyWords-:{important_keywords}\\nImportant Entities-:{important_entities}\")\n",
    "    important_words = set(important_keywords + important_entities)\n",
    "    sentences = sent_tokenize(input_text)\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "    cosine_similarities = linear_kernel(tfidf_matrix[0:1], tfidf_matrix).flatten()\n",
    "\n",
    "    if randomize:\n",
    "        np.random.shuffle(cosine_similarities)\n",
    "\n",
    "    related_sentences_indices = cosine_similarities.argsort()[:-num_sentences:-1]\n",
    "    important_sentences = [sentences[i] for i in related_sentences_indices if any(kw.lower() in sentences[i].lower() for kw in important_words)]\n",
    "    \n",
    "    context_weightage = {\n",
    "        'general': 1,\n",
    "        'story': 1.5,\n",
    "        'report': 1.2,\n",
    "        'article': 1.3\n",
    "    }\n",
    "    \n",
    "    num_output_sentences = max(2, int(detail_level * len(important_sentences) / 5 * context_weightage.get(context_type, 1)))\n",
    "    \n",
    "    if randomize:\n",
    "        selected_sentences = np.random.choice(important_sentences, size=num_output_sentences, replace=False)\n",
    "    else:\n",
    "        selected_sentences = sorted(important_sentences[:num_output_sentences], key=lambda x: sentences.index(x))\n",
    "    \n",
    "    return ' '.join(selected_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important KeyWords-:['driven', 'holds', 'everyday', 'best', 'argues']\n",
      "Important Entities-:['today', 'julie shah', 'mit', 'more than 10 years', 'brady', 'seattle', 'hri', 'amazon']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Amazon, naturally, argues that the machines have the effect of removing physical labor burden from human employees. At today’s Delivering the Future event at a fulfillment center south of Seattle, the company announced that it will be teaming with MIT and the Ipos research firm to determine how these systems will impact work.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_detailed_summarize_premium_varibility(\"\"\"Mention automation and someone will invariably (and understandably) mention its impact on jobs. There are a lot of opposing views on the subject, of course, but the one thing everyone seems to agree on is that robotics and AI will have a profound impact on human jobs, going forward.\n",
    "\n",
    "At today’s Delivering the Future event at a fulfillment center south of Seattle, the company announced that it will be teaming with MIT and the Ipos research firm to determine how these systems will impact work.\n",
    "\n",
    "The subject is obviously an important one for Amazon. Not only is the retail giant a massive employer, it’s been deploying robotics in its fulfillment centers for over a decade. The direct impact they’ve had on human workers has been the subject of debate ever since. Amazon, naturally, argues that the machines have the effect of removing physical labor burden from human employees.\n",
    "\n",
    "Critics, on the other hand, have suggested that robots make human jobs more robotic — a potential issue for work that is highly repetitive. There’s also the big question of job numbers. Proponents of automation suggest the technology will create more and better jobs. The opposing view holds that many existing blue collar-jobs will be displaced, and upskilling humans to work with robots is easier said than done.\n",
    "\n",
    "The study seems less concerned with actual job numbers, and more with how human employees and the public feel about the inevitable increase of robotics and AI in warehouses, manufacturing facilities and other industrial settings.\n",
    "\n",
    "Amazon Robotics’ Chief Technologist Tye Brady did, however, address the question of job numbers ahead of today’s event, noting:\n",
    "\n",
    "We have more than 750,000 mobile robots in our operations and thousands of other robotic systems that help move, sort, identify and package customer orders. It’s taken us more than 10 years to reach this scale. During that time, Amazon has hired hundreds of thousands of employees to work in our operations. We take a purpose-driven approach to how we design and deploy technology at our facilities and we consistently prioritize using robots to support safety and ease everyday tasks for our employees.\n",
    "\n",
    "The study will applied to key facets of robotic developments, including the discipline of human-robot interaction (HRI), a field that pretty much does what it says on the tin.\n",
    "\n",
    "“The key to effective teamwork is building a shared understanding of what our partners will do and what they will need to be successful,” says MIT’s Julie Shah “Our research shows that the best way to optimize human-robot team performance is to develop robots that are active collaborators in helping a human to learn about their capabilities, limitations and behaviors.”\n",
    "\n",
    "\"\"\",1,'article',randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important KeyWords-:['singing', 'legacy', 'instead', 'mystery', 'children']\n",
      "Important Entities-:['the next day', 'mara', 'larksville', 'recent years', 'old guardian', 'this year']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It spoke of an ancient pact it had made with the founders of Larksville. In the heart of a quaint town named Larksville, an ancient oak tree stood tall. Instead, it marked a new beginning. However, in recent years, as the town modernized, many had forgotten the legend, leading Old Guardian to feel abandoned and unloved.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_detailed_summarize_premium_varibility(\"\"\"In the heart of a quaint town named Larksville, an ancient oak tree stood tall. It had seen many seasons come and go, with children playing around its trunk in summer and couples seeking shelter beneath its expansive branches during rain. However, this year was different.\n",
    "\n",
    "As autumn approached, the tree, which locals affectionately called \"Old Guardian\", began to shed its leaves earlier than usual. The townspeople were puzzled. Was the tree finally succumbing to age?\n",
    "\n",
    "Mara, a young girl with fiery red hair and a penchant for adventure, decided to uncover the mystery. Every day after school, she would sit by Old Guardian, reading books and observing its changes. As days turned into weeks, only one leaf remained on the tree, clinging desperately to a fragile branch.\n",
    "\n",
    "One chilly evening, as Mara was about to head home, she heard a soft whisper. To her astonishment, it was coming from the tree. Old Guardian had a story to tell.\n",
    "\n",
    "It spoke of an ancient pact it had made with the founders of Larksville. The tree would stand guard over the town, protecting it from harm. In return, it asked for respect and care from its inhabitants. However, in recent years, as the town modernized, many had forgotten the legend, leading Old Guardian to feel abandoned and unloved.\n",
    "\n",
    "Mara, moved by the tree's tale, decided to act. She gathered the town's children and narrated Old Guardian's story. The next day, the townspeople came together to celebrate the tree, singing songs and sharing tales of its legacy.\n",
    "\n",
    "As winter approached, the last leaf fell, but it wasn't a sign of the tree's end. Instead, it marked a new beginning. The following spring, Old Guardian sprouted more leaves than ever before, standing tall and proud, with the entire town of Larksville by its side.\n",
    "\n",
    "\"\"\",1,'story',randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important KeyWords-:['mark', 'awards', 'launched', 'eligible', 'left']\n",
      "Important Entities-:['two', '30-day', 'tim rathschmidt', '1', 'ethereum', 'gifs', 'reddit', 'community points', 'one', 'faq', 'at least 10', 'vaults', 'early november', '2022', 'arbitrum nova', '48-hour', 'later that month', 'the contributor program']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Once the program is fully phased out, beta participants will no longer see their points in their Vaults, and will no longer earn points in their communities. “Part of why we’re moving past this product is that we’ve already launched, or are actively investing in, several products that accomplish what the Community Points program was trying to accomplish, while being easier to adopt and understand.”\\n\\nHe added that the special features that Community Points can buy, like gifs, should be available to any community. Rathschmidt noted that the company isn’t phasing out Community Points to make way for the Contributor Program, but rather to prioritize on programs that are “more set up to scale and benefit more users,” like the Contributor Program.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_detailed_summarize_premium_varibility(\"\"\"Reddit is winding down Community Points — the blockchain-based “internet points” program designed to reward creators and developers — in favor of prioritizing rewards programs that are less difficult to scale.\n",
    "\n",
    "“Though we saw some future opportunities for Community Points, the resourcing needed was unfortunately too high to justify,” Reddit’s director of consumer and product communications Tim Rathschmidt told TechCrunch. “The regulatory environment has since added to that effort. Though the moderators and communities that supported Community Points have been incredible partners — as it’s evolved, the product is no longer set up to scale.”\n",
    "\n",
    "Community Points, which will be phased out by early November, were promoted as a chance for Redditors to “own” a piece of their community. First launched in 2020, Community Points were awarded to users who positively engaged in select subreddits in order to incentivize better content and conversation. The points were essentially interchangeable Ethereum tokens stored in Reddit’s Vault, which operated as a cryptocurrency wallet.\n",
    "\n",
    "Once awarded, neither Reddit nor moderators could take back another user’s Community Points. The points could be used on special features, like memberships that unlocked unique badges and animated emojis. Once spent, the points were “burned.”\n",
    "\n",
    "As a measure of “reputation,” Community Points were displayed next to usernames in participating subreddits to mark the community’s biggest contributors. Since the points were on the blockchain, the program aimed to allow users to display their “reputation” anywhere online, and could be embedded in other sites or apps. If users were banned from Reddit, their points would still exist on the blockchain, but they would lose access to their Vault — rendering the points useless.\n",
    "\n",
    "But scaling Community Points proved to be an immense challenge for Reddit. The pilot program originally used Ethereum, which had high transaction fees and limited bandwidth.\n",
    "\n",
    "“Putting all Reddit users on the main Ethereum network, for example, would be infeasible and prohibitively expensive,” the Community Points page said. “Therefore, we have researched heavily into solutions that are decentralized, secure and yet highly scalable.”\n",
    "\n",
    "Reddit moved Community Points to Arbitrum Nova in 2022, which is built “on top” of Ethereum.\n",
    "\n",
    "“This enables it to apply scaling technologies that enable ultra-low-cost transactions, very high energy efficiency and strong security guarantees,” the FAQ stated.\n",
    "\n",
    "\n",
    "\n",
    "But even that was impractical for Reddit. In the years since launching Community Points, Reddit has rolled out a number of community incentives, like the moderator rewards program and the Contributor Program, which awards actual money by allowing eligible users to convert their Reddit gold and karma into cash. Under the Contributor Program, Redditors who earn at least 10 gold within a 30-day period are eligible for a monthly withdrawal. Reddit users who have over 5,000 karma (total upvotes) can earn $1 per gold.\n",
    "\n",
    "“We’re still working on ways to improve community governance and empower communities and contributions,” Rathschmidt said. “Part of why we’re moving past this product is that we’ve already launched, or are actively investing in, several products that accomplish what the Community Points program was trying to accomplish, while being easier to adopt and understand.”\n",
    "\n",
    "He added that the special features that Community Points can buy, like gifs, should be available to any community. Once the program is fully phased out, beta participants will no longer see their points in their Vaults, and will no longer earn points in their communities. Although Rathschmidt said he couldn’t give an exact count of the number of subreddits affected by the cut, he admitted that “you’d be able to count them on one hand and have a finger or two left over.”\n",
    "\n",
    "It’s not the only rewards program that Reddit has killed this year. Earlier this year, Reddit announced the end of its coin system, which allowed users to purchase Gold and other currency to award other users. The announcement came in the aftermath of the sitewide protests against Reddit’s API changes, which culminated in a 48-hour blackout of over 8,000 subreddits, and was wildly unpopular among Reddit’s already jaded users. Awards and existing coins under the previous reward program were available until mid-September. Reddit announced the Contributor Program later that month.\n",
    "\n",
    "Rathschmidt noted that the company isn’t phasing out Community Points to make way for the Contributor Program, but rather to prioritize on programs that are “more set up to scale and benefit more users,” like the Contributor Program.\n",
    "\n",
    "“It’s one example. Now, we’re able to scale several products that accomplish what the Community Points program was trying to accomplish — like subreddit karma and gifs,” he continued. “Many of the benefits of Community Points have already been built into the platform.”\"\"\",0.5,'article',randomize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".AI_service",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
